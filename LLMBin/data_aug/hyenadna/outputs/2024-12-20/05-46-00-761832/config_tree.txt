CONFIG
├── train
│   └── seed: 2222                                                                                                                                  
│       interval: step                                                                                                                              
│       monitor: test/loss                                                                                                                          
│       mode: min                                                                                                                                   
│       ema: 0.0                                                                                                                                    
│       test: false                                                                                                                                 
│       debug: false                                                                                                                                
│       ignore_warnings: false                                                                                                                      
│       state:                                                                                                                                      
│         mode: null                                                                                                                                
│         n_context: 0                                                                                                                              
│         n_context_eval: 0                                                                                                                         
│       ckpt: null                                                                                                                                  
│       disable_dataset: false                                                                                                                      
│       validate_at_start: false                                                                                                                    
│       pretrained_model_path: null                                                                                                                 
│       pretrained_model_strict_load: true                                                                                                          
│       pretrained_model_state_hook:                                                                                                                
│         _name_: null                                                                                                                              
│       post_init_hook:                                                                                                                             
│         _name_: null                                                                                                                              
│       layer_decay:                                                                                                                                
│         _name_: null                                                                                                                              
│         decay: 0.7                                                                                                                                
│       gpu_mem: 41                                                                                                                                 
│       global_batch_size: 256                                                                                                                      
│                                                                                                                                                   
├── tolerance
│   └── logdir: ./resume                                                                                                                            
│       id: null                                                                                                                                    
│                                                                                                                                                   
├── wandb
│   └── None                                                                                                                                        
├── trainer
│   └── _target_: pytorch_lightning.Trainer                                                                                                         
│       devices: 1                                                                                                                                  
│       accelerator: gpu                                                                                                                            
│       accumulate_grad_batches: 1                                                                                                                  
│       max_epochs: 100                                                                                                                             
│       gradient_clip_val: 1.0                                                                                                                      
│       log_every_n_steps: 10                                                                                                                       
│       limit_train_batches: 1.0                                                                                                                    
│       limit_val_batches: 1.0                                                                                                                      
│       num_nodes: 1                                                                                                                                
│       precision: 16                                                                                                                               
│                                                                                                                                                   
├── loader
│   └── batch_size: 50                                                                                                                              
│       num_workers: 4                                                                                                                              
│       pin_memory: true                                                                                                                            
│       drop_last: true                                                                                                                             
│                                                                                                                                                   
├── dataset
│   └── _name_: hg38                                                                                                                                
│       bed_file: /home1/jialh/metaHiC/LLMs/hyena-dna/data/hg38/human-sequences.bed                                                                 
│       fasta_file: /home1/jialh/metaHiC/LLMs/hyena-dna/data/hg38/hg38.ml.fa                                                                        
│       dataset_name: hg38                                                                                                                          
│       tokenizer_name: char                                                                                                                        
│       cache_dir: null                                                                                                                             
│       max_length: 1024                                                                                                                            
│       add_eos: true                                                                                                                               
│       batch_size: 256                                                                                                                             
│       batch_size_eval: 512                                                                                                                        
│       num_workers: 12                                                                                                                             
│       shuffle: true                                                                                                                               
│       pin_memory: true                                                                                                                            
│       max_length_val: 1024                                                                                                                        
│       max_length_test: 1024                                                                                                                       
│       pad_max_length: null                                                                                                                        
│       rc_aug: false                                                                                                                               
│       use_fixed_len_val: false                                                                                                                    
│       replace_N_token: false                                                                                                                      
│       pad_interval: false                                                                                                                         
│                                                                                                                                                   
├── optimizer
│   └── _name_: adamw                                                                                                                               
│       lr: 0.0006                                                                                                                                  
│       weight_decay: 0.1                                                                                                                           
│       betas:                                                                                                                                      
│       - 0.9                                                                                                                                       
│       - 0.999                                                                                                                                     
│                                                                                                                                                   
├── scheduler
│   └── _name_: cosine_warmup_timm                                                                                                                  
│       t_in_epochs: false                                                                                                                          
│       t_initial: 381500                                                                                                                           
│       lr_min: 5.9999999999999995e-05                                                                                                              
│       warmup_lr_init: 1.0e-06                                                                                                                     
│       warmup_t: 3815.0                                                                                                                            
│                                                                                                                                                   
├── callbacks
│   └── learning_rate_monitor:                                                                                                                      
│         logging_interval: step                                                                                                                    
│       timer:                                                                                                                                      
│         step: true                                                                                                                                
│         inter_step: false                                                                                                                         
│         epoch: true                                                                                                                               
│         val: true                                                                                                                                 
│       params:                                                                                                                                     
│         total: true                                                                                                                               
│         trainable: true                                                                                                                           
│         fixed: true                                                                                                                               
│       model_checkpoint:                                                                                                                           
│         monitor: test/loss                                                                                                                        
│         mode: min                                                                                                                                 
│         save_top_k: 1                                                                                                                             
│         save_last: true                                                                                                                           
│         dirpath: checkpoints/                                                                                                                     
│         filename: test/loss                                                                                                                       
│         auto_insert_metric_name: false                                                                                                            
│         verbose: true                                                                                                                             
│                                                                                                                                                   
├── task
│   └── _name_: lm                                                                                                                                  
│       loss: cross_entropy                                                                                                                         
│       torchmetrics:                                                                                                                               
│       - perplexity                                                                                                                                
│       - num_tokens                                                                                                                                
│                                                                                                                                                   
├── encoder
│   └── None                                                                                                                                        
├── decoder
│   └── None                                                                                                                                        
└── model
    └── _name_: lm                                                                                                                                  
        d_model: 128                                                                                                                                
        n_layer: 2                                                                                                                                  
        d_inner: 512                                                                                                                                
        vocab_size: 12                                                                                                                              
        resid_dropout: 0.0                                                                                                                          
        embed_dropout: 0.1                                                                                                                          
        fused_mlp: false                                                                                                                            
        fused_dropout_add_ln: false                                                                                                                 
        checkpoint_mixer: false                                                                                                                     
        checkpoint_mlp: false                                                                                                                       
        residual_in_fp32: true                                                                                                                      
        pad_vocab_size_multiple: 8                                                                                                                  
        layer:                                                                                                                                      
          _name_: hyena                                                                                                                             
          emb_dim: 5                                                                                                                                
          filter_order: 64                                                                                                                          
          short_filter_order: 3                                                                                                                     
          l_max: 1026                                                                                                                               
          modulate: true                                                                                                                            
          w: 10                                                                                                                                     
          lr: 0.0006                                                                                                                                
          wd: 0.0                                                                                                                                   
          lr_pos_emb: 0.0                                                                                                                           
                                                                                                                                                    
